{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Classification (one more time) with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/iris.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds[:,:4].astype(float)\n",
    "Y = ds[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the classes for a neural net\n",
    "The output layer is going to be 3 nodes each node corresponding to one of our classes.  So, we'll one-hot the labels so that each column will map to one of the output layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "enc_Y = encoder.transform(Y)\n",
    "dummy_y = np_utils.to_categorical(enc_Y)\n",
    "dummy_y[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "* relu - rectified linear unit \n",
    "\n",
    "$$f(x) = \\begin{cases}0 &  x < 0 \\\\ 1 & x >= 1 \\end{cases}$$\n",
    "\n",
    "* softmax - turns the output value of each output layer neuron into a probability that it is 'correct'. In our case the index of the neuron with the highest probability gives us back our original label encoded value for the kind of iris it is.\n",
    "\n",
    "### Loss\n",
    "\n",
    "The categorical_crossentropy is a measure of error just like mean squared error that we use with neural networks when we have mulitple classes.\n",
    "\n",
    "\n",
    "### optimizer\n",
    "\n",
    "* adam - features an adaptive learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=build_model, epochs=300, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)#, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model using k-Fold cross validation\n",
    "\n",
    "* Repeat the following K times\n",
    "  * Take the original data set and break it up into k groups\n",
    "  * Use k-1 groups as the training set\n",
    "  * test on on the last group\n",
    "  * remember which group was used as test this time so a different group can be used next time.\n",
    "\n",
    "This is even nicer/better than the manual train/test split method as you get to check it on a bunch of different train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93333334, 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.93333334, 0.86666667, 1.        , 0.93333334, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The traditional fit predict route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.9411 - acc: 0.3333 - val_loss: 2.8514 - val_acc: 0.3333\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 72us/step - loss: 2.8434 - acc: 0.3333 - val_loss: 2.7556 - val_acc: 0.3333\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 74us/step - loss: 2.7482 - acc: 0.3333 - val_loss: 2.6609 - val_acc: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 63us/step - loss: 2.6554 - acc: 0.3333 - val_loss: 2.5691 - val_acc: 0.3333\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 49us/step - loss: 2.5619 - acc: 0.3333 - val_loss: 2.4782 - val_acc: 0.3333\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 2.4719 - acc: 0.3333 - val_loss: 2.3887 - val_acc: 0.3333\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 2.3810 - acc: 0.3333 - val_loss: 2.3009 - val_acc: 0.3333\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 2.2934 - acc: 0.3333 - val_loss: 2.2146 - val_acc: 0.3333\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 61us/step - loss: 2.2099 - acc: 0.3333 - val_loss: 2.1307 - val_acc: 0.3333\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 58us/step - loss: 2.1240 - acc: 0.3333 - val_loss: 2.0506 - val_acc: 0.3333\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 55us/step - loss: 2.0448 - acc: 0.3333 - val_loss: 1.9732 - val_acc: 0.3333\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 57us/step - loss: 1.9662 - acc: 0.3333 - val_loss: 1.8986 - val_acc: 0.3333\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 1.8925 - acc: 0.3333 - val_loss: 1.8267 - val_acc: 0.3333\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 53us/step - loss: 1.8218 - acc: 0.3333 - val_loss: 1.7586 - val_acc: 0.3333\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 1.7534 - acc: 0.3333 - val_loss: 1.6946 - val_acc: 0.3333\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 56us/step - loss: 1.6900 - acc: 0.3333 - val_loss: 1.6347 - val_acc: 0.3333\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 58us/step - loss: 1.6320 - acc: 0.3333 - val_loss: 1.5794 - val_acc: 0.3333\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 59us/step - loss: 1.5767 - acc: 0.3333 - val_loss: 1.5288 - val_acc: 0.3333\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 59us/step - loss: 1.5257 - acc: 0.3333 - val_loss: 1.4827 - val_acc: 0.3333\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 1.4798 - acc: 0.3333 - val_loss: 1.4402 - val_acc: 0.3333\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 1.4377 - acc: 0.3333 - val_loss: 1.4012 - val_acc: 0.3333\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 1.3985 - acc: 0.3333 - val_loss: 1.3653 - val_acc: 0.3333\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 1.3621 - acc: 0.3333 - val_loss: 1.3321 - val_acc: 0.3333\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 1.3298 - acc: 0.3333 - val_loss: 1.3012 - val_acc: 0.3400\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 1.2980 - acc: 0.3467 - val_loss: 1.2724 - val_acc: 0.3533\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 1.2707 - acc: 0.3600 - val_loss: 1.2456 - val_acc: 0.3667\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 1.2441 - acc: 0.3733 - val_loss: 1.2209 - val_acc: 0.3800\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 50us/step - loss: 1.2193 - acc: 0.3800 - val_loss: 1.1981 - val_acc: 0.4000\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 50us/step - loss: 1.1962 - acc: 0.4000 - val_loss: 1.1768 - val_acc: 0.4133\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 63us/step - loss: 1.1748 - acc: 0.4133 - val_loss: 1.1566 - val_acc: 0.4667\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 51us/step - loss: 1.1548 - acc: 0.4667 - val_loss: 1.1375 - val_acc: 0.4667\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 62us/step - loss: 1.1362 - acc: 0.4667 - val_loss: 1.1199 - val_acc: 0.4867\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 1.1186 - acc: 0.4867 - val_loss: 1.1035 - val_acc: 0.4933\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 1.1020 - acc: 0.4933 - val_loss: 1.0882 - val_acc: 0.5200\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 1.0863 - acc: 0.5200 - val_loss: 1.0734 - val_acc: 0.5267\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 1.0736 - acc: 0.5267 - val_loss: 1.0597 - val_acc: 0.5333\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 49us/step - loss: 1.0586 - acc: 0.5333 - val_loss: 1.0473 - val_acc: 0.5467\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 56us/step - loss: 1.0460 - acc: 0.5467 - val_loss: 1.0354 - val_acc: 0.5467\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 1.0342 - acc: 0.5467 - val_loss: 1.0241 - val_acc: 0.5400\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 1.0232 - acc: 0.5400 - val_loss: 1.0134 - val_acc: 0.5467\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 1.0128 - acc: 0.5533 - val_loss: 1.0036 - val_acc: 0.5533\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 1.0030 - acc: 0.5533 - val_loss: 0.9945 - val_acc: 0.5533\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.9938 - acc: 0.5533 - val_loss: 0.9862 - val_acc: 0.5533\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.9859 - acc: 0.5533 - val_loss: 0.9784 - val_acc: 0.5800\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.9775 - acc: 0.5800 - val_loss: 0.9710 - val_acc: 0.5800\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.9709 - acc: 0.5800 - val_loss: 0.9640 - val_acc: 0.5867\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 55us/step - loss: 0.9636 - acc: 0.5867 - val_loss: 0.9576 - val_acc: 0.5933\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.9578 - acc: 0.5933 - val_loss: 0.9515 - val_acc: 0.6000\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.9510 - acc: 0.5933 - val_loss: 0.9458 - val_acc: 0.6000\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.9456 - acc: 0.6000 - val_loss: 0.9401 - val_acc: 0.6000\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.9395 - acc: 0.6000 - val_loss: 0.9339 - val_acc: 0.6200\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.9335 - acc: 0.6200 - val_loss: 0.9275 - val_acc: 0.6600\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.9272 - acc: 0.6733 - val_loss: 0.9211 - val_acc: 0.6867\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 50us/step - loss: 0.9209 - acc: 0.6933 - val_loss: 0.9148 - val_acc: 0.7200\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 56us/step - loss: 0.9146 - acc: 0.7200 - val_loss: 0.9087 - val_acc: 0.7533\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.9082 - acc: 0.7533 - val_loss: 0.9025 - val_acc: 0.7800\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.9022 - acc: 0.7800 - val_loss: 0.8963 - val_acc: 0.8133\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.8961 - acc: 0.8133 - val_loss: 0.8905 - val_acc: 0.8333\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.8900 - acc: 0.8333 - val_loss: 0.8846 - val_acc: 0.8333\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.8843 - acc: 0.8333 - val_loss: 0.8787 - val_acc: 0.8267\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 57us/step - loss: 0.8782 - acc: 0.8267 - val_loss: 0.8728 - val_acc: 0.8400\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.8723 - acc: 0.8400 - val_loss: 0.8669 - val_acc: 0.8333\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.8665 - acc: 0.8333 - val_loss: 0.8611 - val_acc: 0.8133\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.8605 - acc: 0.8133 - val_loss: 0.8552 - val_acc: 0.7800\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.8546 - acc: 0.7733 - val_loss: 0.8494 - val_acc: 0.7400\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.8495 - acc: 0.7400 - val_loss: 0.8439 - val_acc: 0.7333\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.8435 - acc: 0.7333 - val_loss: 0.8385 - val_acc: 0.7067\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 38us/step - loss: 0.8383 - acc: 0.7067 - val_loss: 0.8331 - val_acc: 0.6867\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.8327 - acc: 0.6867 - val_loss: 0.8277 - val_acc: 0.6867\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.8274 - acc: 0.6867 - val_loss: 0.8224 - val_acc: 0.6933\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.8220 - acc: 0.6867 - val_loss: 0.8171 - val_acc: 0.6867\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.8168 - acc: 0.6867 - val_loss: 0.8117 - val_acc: 0.6867\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.8113 - acc: 0.6867 - val_loss: 0.8062 - val_acc: 0.6867\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.8057 - acc: 0.6867 - val_loss: 0.8005 - val_acc: 0.6867\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.8000 - acc: 0.6867 - val_loss: 0.7947 - val_acc: 0.6867\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.7943 - acc: 0.6867 - val_loss: 0.7888 - val_acc: 0.6867\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.7883 - acc: 0.6867 - val_loss: 0.7828 - val_acc: 0.6867\n",
      "Epoch 78/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.7823 - acc: 0.6867 - val_loss: 0.7768 - val_acc: 0.6867\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.7764 - acc: 0.6867 - val_loss: 0.7709 - val_acc: 0.6800\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.7703 - acc: 0.6800 - val_loss: 0.7650 - val_acc: 0.6800\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.7644 - acc: 0.6800 - val_loss: 0.7592 - val_acc: 0.6800\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 51us/step - loss: 0.7589 - acc: 0.6800 - val_loss: 0.7534 - val_acc: 0.6800\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.7529 - acc: 0.6800 - val_loss: 0.7478 - val_acc: 0.6800\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.7474 - acc: 0.6800 - val_loss: 0.7422 - val_acc: 0.6733\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.7417 - acc: 0.6733 - val_loss: 0.7366 - val_acc: 0.6733\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 61us/step - loss: 0.7362 - acc: 0.6733 - val_loss: 0.7310 - val_acc: 0.6733\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.7305 - acc: 0.6733 - val_loss: 0.7255 - val_acc: 0.6733\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.7251 - acc: 0.6733 - val_loss: 0.7200 - val_acc: 0.6733\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.7196 - acc: 0.6733 - val_loss: 0.7146 - val_acc: 0.6733\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.7143 - acc: 0.6733 - val_loss: 0.7092 - val_acc: 0.6733\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.7087 - acc: 0.6733 - val_loss: 0.7038 - val_acc: 0.6733\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.7034 - acc: 0.6733 - val_loss: 0.6983 - val_acc: 0.6733\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.6979 - acc: 0.6733 - val_loss: 0.6930 - val_acc: 0.6733\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.6927 - acc: 0.6733 - val_loss: 0.6879 - val_acc: 0.6733\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.6874 - acc: 0.6733 - val_loss: 0.6827 - val_acc: 0.6733\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.6824 - acc: 0.6733 - val_loss: 0.6776 - val_acc: 0.6800\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.6773 - acc: 0.6800 - val_loss: 0.6720 - val_acc: 0.6800\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.6717 - acc: 0.6800 - val_loss: 0.6663 - val_acc: 0.6800\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.6660 - acc: 0.6800 - val_loss: 0.6605 - val_acc: 0.6933\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.6602 - acc: 0.6933 - val_loss: 0.6550 - val_acc: 0.7333\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.6545 - acc: 0.7400 - val_loss: 0.6492 - val_acc: 0.7933\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.6488 - acc: 0.7933 - val_loss: 0.6442 - val_acc: 0.8067\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.6436 - acc: 0.8200 - val_loss: 0.6397 - val_acc: 0.8733\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.6395 - acc: 0.8733 - val_loss: 0.6364 - val_acc: 0.8800\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.6360 - acc: 0.8800 - val_loss: 0.6330 - val_acc: 0.8800\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.6327 - acc: 0.8800 - val_loss: 0.6295 - val_acc: 0.8800\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.6292 - acc: 0.8800 - val_loss: 0.6258 - val_acc: 0.8800\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.6255 - acc: 0.8800 - val_loss: 0.6217 - val_acc: 0.8867\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.6217 - acc: 0.8867 - val_loss: 0.6174 - val_acc: 0.8800\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.6171 - acc: 0.8800 - val_loss: 0.6132 - val_acc: 0.8867\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.6128 - acc: 0.8933 - val_loss: 0.6091 - val_acc: 0.8800\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.6085 - acc: 0.8800 - val_loss: 0.6052 - val_acc: 0.8200\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.6048 - acc: 0.8200 - val_loss: 0.6018 - val_acc: 0.7933\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.6019 - acc: 0.7933 - val_loss: 0.5987 - val_acc: 0.7800\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5984 - acc: 0.7733 - val_loss: 0.5956 - val_acc: 0.7467\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.5953 - acc: 0.7467 - val_loss: 0.5926 - val_acc: 0.7400\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 51us/step - loss: 0.5925 - acc: 0.7400 - val_loss: 0.5896 - val_acc: 0.7333\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.5893 - acc: 0.7333 - val_loss: 0.5862 - val_acc: 0.7400\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.5857 - acc: 0.7533 - val_loss: 0.5828 - val_acc: 0.8000\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 51us/step - loss: 0.5826 - acc: 0.8000 - val_loss: 0.5797 - val_acc: 0.8133\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 50us/step - loss: 0.5795 - acc: 0.8200 - val_loss: 0.5769 - val_acc: 0.8400\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.5767 - acc: 0.8400 - val_loss: 0.5742 - val_acc: 0.8600\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5740 - acc: 0.8600 - val_loss: 0.5716 - val_acc: 0.8800\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.5714 - acc: 0.8800 - val_loss: 0.5691 - val_acc: 0.9000\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.5687 - acc: 0.9000 - val_loss: 0.5667 - val_acc: 0.9133\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5664 - acc: 0.9133 - val_loss: 0.5645 - val_acc: 0.9000\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.5644 - acc: 0.8933 - val_loss: 0.5625 - val_acc: 0.9200\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.5624 - acc: 0.9200 - val_loss: 0.5601 - val_acc: 0.9200\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.5599 - acc: 0.9200 - val_loss: 0.5575 - val_acc: 0.9200\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5573 - acc: 0.9200 - val_loss: 0.5547 - val_acc: 0.9133\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.5546 - acc: 0.9200 - val_loss: 0.5520 - val_acc: 0.9000\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.5520 - acc: 0.9000 - val_loss: 0.5495 - val_acc: 0.9067\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.5493 - acc: 0.9067 - val_loss: 0.5470 - val_acc: 0.9133\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.5469 - acc: 0.9133 - val_loss: 0.5446 - val_acc: 0.9133\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.5444 - acc: 0.9133 - val_loss: 0.5422 - val_acc: 0.9067\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 63us/step - loss: 0.5420 - acc: 0.9067 - val_loss: 0.5398 - val_acc: 0.8933\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.5397 - acc: 0.8933 - val_loss: 0.5376 - val_acc: 0.8667\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5376 - acc: 0.8600 - val_loss: 0.5356 - val_acc: 0.8600\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.5354 - acc: 0.8600 - val_loss: 0.5335 - val_acc: 0.8533\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.5333 - acc: 0.8467 - val_loss: 0.5316 - val_acc: 0.8400\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.5314 - acc: 0.8400 - val_loss: 0.5298 - val_acc: 0.8333\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5295 - acc: 0.8333 - val_loss: 0.5281 - val_acc: 0.8067\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.5278 - acc: 0.8000 - val_loss: 0.5266 - val_acc: 0.7800\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 57us/step - loss: 0.5263 - acc: 0.7800 - val_loss: 0.5251 - val_acc: 0.7667\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.5250 - acc: 0.7600 - val_loss: 0.5238 - val_acc: 0.7467\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.5236 - acc: 0.7467 - val_loss: 0.5223 - val_acc: 0.7400\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.5223 - acc: 0.7400 - val_loss: 0.5206 - val_acc: 0.7400\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 57us/step - loss: 0.5205 - acc: 0.7400 - val_loss: 0.5185 - val_acc: 0.7400\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.5184 - acc: 0.7400 - val_loss: 0.5165 - val_acc: 0.7467\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.5164 - acc: 0.7467 - val_loss: 0.5147 - val_acc: 0.7467\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.5146 - acc: 0.7467 - val_loss: 0.5129 - val_acc: 0.7533\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.5127 - acc: 0.7533 - val_loss: 0.5108 - val_acc: 0.7667\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 56us/step - loss: 0.5108 - acc: 0.7667 - val_loss: 0.5085 - val_acc: 0.7933\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.5083 - acc: 0.7933 - val_loss: 0.5063 - val_acc: 0.8200\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 56us/step - loss: 0.5060 - acc: 0.8200 - val_loss: 0.5042 - val_acc: 0.8400\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.5039 - acc: 0.8400 - val_loss: 0.5022 - val_acc: 0.8533\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.5020 - acc: 0.8533 - val_loss: 0.5004 - val_acc: 0.8667\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.5004 - acc: 0.8667 - val_loss: 0.4988 - val_acc: 0.8867\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4985 - acc: 0.8933 - val_loss: 0.4974 - val_acc: 0.9067\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4975 - acc: 0.9067 - val_loss: 0.4960 - val_acc: 0.9133\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4959 - acc: 0.9133 - val_loss: 0.4946 - val_acc: 0.9200\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.4945 - acc: 0.9200 - val_loss: 0.4932 - val_acc: 0.9333\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4932 - acc: 0.9333 - val_loss: 0.4917 - val_acc: 0.9333\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.4916 - acc: 0.9333 - val_loss: 0.4901 - val_acc: 0.9267\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 61us/step - loss: 0.4900 - acc: 0.9267 - val_loss: 0.4885 - val_acc: 0.9267\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.4884 - acc: 0.9267 - val_loss: 0.4870 - val_acc: 0.9267\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 71us/step - loss: 0.4868 - acc: 0.9267 - val_loss: 0.4854 - val_acc: 0.9133\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 56us/step - loss: 0.4853 - acc: 0.9133 - val_loss: 0.4838 - val_acc: 0.9067\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.4837 - acc: 0.9000 - val_loss: 0.4823 - val_acc: 0.9000\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.4823 - acc: 0.9000 - val_loss: 0.4809 - val_acc: 0.9000\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.4808 - acc: 0.9000 - val_loss: 0.4795 - val_acc: 0.9000\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4794 - acc: 0.9000 - val_loss: 0.4780 - val_acc: 0.9000\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.4779 - acc: 0.9000 - val_loss: 0.4766 - val_acc: 0.9000\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4765 - acc: 0.9000 - val_loss: 0.4751 - val_acc: 0.9000\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4750 - acc: 0.9000 - val_loss: 0.4738 - val_acc: 0.9000\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.4736 - acc: 0.9000 - val_loss: 0.4724 - val_acc: 0.9000\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4771 - acc: 0.898 - 0s 57us/step - loss: 0.4723 - acc: 0.9000 - val_loss: 0.4711 - val_acc: 0.9000\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 38us/step - loss: 0.4710 - acc: 0.9000 - val_loss: 0.4698 - val_acc: 0.8933\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4697 - acc: 0.8933 - val_loss: 0.4685 - val_acc: 0.8867\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4684 - acc: 0.8867 - val_loss: 0.4673 - val_acc: 0.8800\n",
      "Epoch 181/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 42us/step - loss: 0.4673 - acc: 0.8800 - val_loss: 0.4660 - val_acc: 0.8800\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4659 - acc: 0.8800 - val_loss: 0.4647 - val_acc: 0.8800\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4646 - acc: 0.8800 - val_loss: 0.4634 - val_acc: 0.8867\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4633 - acc: 0.8867 - val_loss: 0.4621 - val_acc: 0.8867\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4620 - acc: 0.8867 - val_loss: 0.4608 - val_acc: 0.8933\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4607 - acc: 0.8933 - val_loss: 0.4595 - val_acc: 0.8933\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4595 - acc: 0.8933 - val_loss: 0.4583 - val_acc: 0.9000\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4583 - acc: 0.9000 - val_loss: 0.4571 - val_acc: 0.9000\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4570 - acc: 0.9000 - val_loss: 0.4559 - val_acc: 0.9000\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4560 - acc: 0.9000 - val_loss: 0.4547 - val_acc: 0.9000\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 37us/step - loss: 0.4546 - acc: 0.9000 - val_loss: 0.4535 - val_acc: 0.9000\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4534 - acc: 0.9000 - val_loss: 0.4523 - val_acc: 0.9067\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4523 - acc: 0.9067 - val_loss: 0.4511 - val_acc: 0.9267\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4511 - acc: 0.9267 - val_loss: 0.4500 - val_acc: 0.9333\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4499 - acc: 0.9333 - val_loss: 0.4490 - val_acc: 0.9533\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 37us/step - loss: 0.4490 - acc: 0.9533 - val_loss: 0.4479 - val_acc: 0.9533\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4478 - acc: 0.9533 - val_loss: 0.4467 - val_acc: 0.9533\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4466 - acc: 0.9533 - val_loss: 0.4455 - val_acc: 0.9533\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4456 - acc: 0.9533 - val_loss: 0.4444 - val_acc: 0.9400\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 37us/step - loss: 0.4443 - acc: 0.9400 - val_loss: 0.4433 - val_acc: 0.9400\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4432 - acc: 0.9400 - val_loss: 0.4422 - val_acc: 0.9400\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4421 - acc: 0.9400 - val_loss: 0.4411 - val_acc: 0.9400\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.4410 - acc: 0.9400 - val_loss: 0.4400 - val_acc: 0.9400\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.4399 - acc: 0.9400 - val_loss: 0.4389 - val_acc: 0.9333\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.4388 - acc: 0.9333 - val_loss: 0.4378 - val_acc: 0.9333\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4377 - acc: 0.9333 - val_loss: 0.4368 - val_acc: 0.9333\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4367 - acc: 0.9333 - val_loss: 0.4357 - val_acc: 0.9200\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4357 - acc: 0.9200 - val_loss: 0.4347 - val_acc: 0.9200\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.9200 - val_loss: 0.4337 - val_acc: 0.9067\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4336 - acc: 0.9067 - val_loss: 0.4328 - val_acc: 0.9067\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.4328 - acc: 0.9067 - val_loss: 0.4320 - val_acc: 0.8933\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.4321 - acc: 0.8933 - val_loss: 0.4311 - val_acc: 0.8933\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4310 - acc: 0.8933 - val_loss: 0.4300 - val_acc: 0.9000\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.4298 - acc: 0.9067 - val_loss: 0.4288 - val_acc: 0.9067\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4288 - acc: 0.9067 - val_loss: 0.4277 - val_acc: 0.9200\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.4276 - acc: 0.9200 - val_loss: 0.4266 - val_acc: 0.9200\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.4265 - acc: 0.9200 - val_loss: 0.4255 - val_acc: 0.9200\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4255 - acc: 0.9200 - val_loss: 0.4245 - val_acc: 0.9200\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4244 - acc: 0.9200 - val_loss: 0.4235 - val_acc: 0.9200\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4235 - acc: 0.9200 - val_loss: 0.4226 - val_acc: 0.9200\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.4226 - acc: 0.9200 - val_loss: 0.4216 - val_acc: 0.9200\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4216 - acc: 0.9200 - val_loss: 0.4206 - val_acc: 0.9200\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 38us/step - loss: 0.4207 - acc: 0.9200 - val_loss: 0.4197 - val_acc: 0.9200\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4196 - acc: 0.9200 - val_loss: 0.4186 - val_acc: 0.9200\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4185 - acc: 0.9200 - val_loss: 0.4176 - val_acc: 0.9400\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4176 - acc: 0.9467 - val_loss: 0.4166 - val_acc: 0.9533\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4165 - acc: 0.9533 - val_loss: 0.4157 - val_acc: 0.9600\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4157 - acc: 0.9600 - val_loss: 0.4148 - val_acc: 0.9667\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4147 - acc: 0.9667 - val_loss: 0.4140 - val_acc: 0.9667\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.4139 - acc: 0.9667 - val_loss: 0.4132 - val_acc: 0.9600\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4131 - acc: 0.9600 - val_loss: 0.4123 - val_acc: 0.9533\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4123 - acc: 0.9533 - val_loss: 0.4115 - val_acc: 0.9533\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4114 - acc: 0.9533 - val_loss: 0.4106 - val_acc: 0.9533\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4106 - acc: 0.9467 - val_loss: 0.4097 - val_acc: 0.9533\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4096 - acc: 0.9533 - val_loss: 0.4086 - val_acc: 0.9667\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4085 - acc: 0.9667 - val_loss: 0.4076 - val_acc: 0.9667\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.4076 - acc: 0.9667 - val_loss: 0.4066 - val_acc: 0.9600\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4065 - acc: 0.9600 - val_loss: 0.4057 - val_acc: 0.9533\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4057 - acc: 0.9533 - val_loss: 0.4049 - val_acc: 0.9533\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.4048 - acc: 0.9533 - val_loss: 0.4040 - val_acc: 0.9533\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 43us/step - loss: 0.4039 - acc: 0.9533 - val_loss: 0.4031 - val_acc: 0.9533\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4030 - acc: 0.9533 - val_loss: 0.4021 - val_acc: 0.9600\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.4020 - acc: 0.9600 - val_loss: 0.4012 - val_acc: 0.9600\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.4011 - acc: 0.9600 - val_loss: 0.4002 - val_acc: 0.9600\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.4002 - acc: 0.9533 - val_loss: 0.3993 - val_acc: 0.9533\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 48us/step - loss: 0.3992 - acc: 0.9533 - val_loss: 0.3985 - val_acc: 0.9533\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.3985 - acc: 0.9467 - val_loss: 0.3977 - val_acc: 0.9200\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3977 - acc: 0.9200 - val_loss: 0.3969 - val_acc: 0.9200\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3968 - acc: 0.9200 - val_loss: 0.3960 - val_acc: 0.9200\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3960 - acc: 0.9200 - val_loss: 0.3951 - val_acc: 0.9333\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3951 - acc: 0.9333 - val_loss: 0.3941 - val_acc: 0.9533\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3940 - acc: 0.9533 - val_loss: 0.3931 - val_acc: 0.9533\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.3929 - acc: 0.9600 - val_loss: 0.3922 - val_acc: 0.9600\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.3923 - acc: 0.9600 - val_loss: 0.3914 - val_acc: 0.9667\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3913 - acc: 0.9667 - val_loss: 0.3906 - val_acc: 0.9667\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.3905 - acc: 0.9667 - val_loss: 0.3898 - val_acc: 0.9733\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 57us/step - loss: 0.3899 - acc: 0.9733 - val_loss: 0.3891 - val_acc: 0.9600\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.3890 - acc: 0.9600 - val_loss: 0.3882 - val_acc: 0.9733\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.3881 - acc: 0.9733 - val_loss: 0.3872 - val_acc: 0.9733\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 55us/step - loss: 0.3873 - acc: 0.9733 - val_loss: 0.3862 - val_acc: 0.9667\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3862 - acc: 0.9667 - val_loss: 0.3853 - val_acc: 0.9667\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.3853 - acc: 0.9667 - val_loss: 0.3845 - val_acc: 0.9667\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3845 - acc: 0.9667 - val_loss: 0.3836 - val_acc: 0.9667\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3835 - acc: 0.9667 - val_loss: 0.3828 - val_acc: 0.9667\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3826 - acc: 0.9667 - val_loss: 0.3820 - val_acc: 0.9733\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 52us/step - loss: 0.3821 - acc: 0.9667 - val_loss: 0.3814 - val_acc: 0.9600\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 57us/step - loss: 0.3813 - acc: 0.9600 - val_loss: 0.3807 - val_acc: 0.9600\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 51us/step - loss: 0.3806 - acc: 0.9600 - val_loss: 0.3801 - val_acc: 0.9600\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3800 - acc: 0.9600 - val_loss: 0.3795 - val_acc: 0.9600\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3795 - acc: 0.9600 - val_loss: 0.3787 - val_acc: 0.9600\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.3787 - acc: 0.9600 - val_loss: 0.3777 - val_acc: 0.9600\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.3777 - acc: 0.9600 - val_loss: 0.3767 - val_acc: 0.9600\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3766 - acc: 0.9600 - val_loss: 0.3757 - val_acc: 0.9600\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3756 - acc: 0.9600 - val_loss: 0.3746 - val_acc: 0.9800\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.3745 - acc: 0.9800 - val_loss: 0.3737 - val_acc: 0.9733\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3737 - acc: 0.9667 - val_loss: 0.3728 - val_acc: 0.9667\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3729 - acc: 0.9667 - val_loss: 0.3720 - val_acc: 0.9667\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3720 - acc: 0.9667 - val_loss: 0.3712 - val_acc: 0.9667\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3712 - acc: 0.9667 - val_loss: 0.3705 - val_acc: 0.9667\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3704 - acc: 0.9667 - val_loss: 0.3697 - val_acc: 0.9667\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.3696 - acc: 0.9667 - val_loss: 0.3689 - val_acc: 0.9733\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3688 - acc: 0.9733 - val_loss: 0.3681 - val_acc: 0.9733\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 57us/step - loss: 0.3681 - acc: 0.9733 - val_loss: 0.3673 - val_acc: 0.9733\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.3672 - acc: 0.9733 - val_loss: 0.3665 - val_acc: 0.9733\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.3664 - acc: 0.9733 - val_loss: 0.3657 - val_acc: 0.9667\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.3657 - acc: 0.9667 - val_loss: 0.3649 - val_acc: 0.9667\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3649 - acc: 0.9667 - val_loss: 0.3642 - val_acc: 0.9667\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3641 - acc: 0.9667 - val_loss: 0.3634 - val_acc: 0.9667\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 43us/step - loss: 0.3633 - acc: 0.9667 - val_loss: 0.3626 - val_acc: 0.9667\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.3625 - acc: 0.9667 - val_loss: 0.3619 - val_acc: 0.9667\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 40us/step - loss: 0.3618 - acc: 0.9667 - val_loss: 0.3612 - val_acc: 0.9600\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 50us/step - loss: 0.3611 - acc: 0.9600 - val_loss: 0.3604 - val_acc: 0.9600\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3604 - acc: 0.9600 - val_loss: 0.3597 - val_acc: 0.9600\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3597 - acc: 0.9600 - val_loss: 0.3589 - val_acc: 0.9600\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.3588 - acc: 0.9600 - val_loss: 0.3582 - val_acc: 0.9600\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 44us/step - loss: 0.3582 - acc: 0.9600 - val_loss: 0.3576 - val_acc: 0.9533\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.3577 - acc: 0.9533 - val_loss: 0.3569 - val_acc: 0.9533\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.3568 - acc: 0.9600 - val_loss: 0.3559 - val_acc: 0.9600\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3558 - acc: 0.9600 - val_loss: 0.3549 - val_acc: 0.9667\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.3549 - acc: 0.9667 - val_loss: 0.3541 - val_acc: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd146383c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(X, dummy_y,\n",
    "          batch_size=128, epochs=300,\n",
    "          verbose=1,\n",
    "          validation_data=(X, dummy_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35371209343274435, 0.9733333333333334]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X, dummy_y,\n",
    "                        verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba lets us see the probabilities and how they correspond to the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6882755e-01, 3.0254379e-02, 9.1800821e-04],\n",
       "       [9.6595043e-01, 3.2416686e-02, 1.6328995e-03],\n",
       "       [9.5972043e-01, 3.8722940e-02, 1.5566356e-03],\n",
       "       [9.2314446e-01, 7.3068842e-02, 3.7867420e-03],\n",
       "       [9.6113563e-01, 3.7802637e-02, 1.0617991e-03],\n",
       "       [9.4380862e-01, 5.4745786e-02, 1.4455033e-03],\n",
       "       [9.2853552e-01, 6.8862565e-02, 2.6018852e-03],\n",
       "       [9.5408779e-01, 4.4298373e-02, 1.6138533e-03],\n",
       "       [9.2526114e-01, 7.0485041e-02, 4.2537968e-03],\n",
       "       [9.5523560e-01, 4.2740766e-02, 2.0236825e-03]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Machine Learning Mastery](https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
